# SentinelBench

This is a collection of challenges for testing AI agents on long-running, persistent monitoring and conditional tasks.

They're designed to be:

- focused on sustained engagement and monitoring capabilities
- testing patience, persistence, and continuous observation  
- requiring agents to maintain state across sessions
- challenging for AI agents due to time and attention requirements
- easy to evaluate
  - each task provides a unique password on successful completion as well as the time it took the agent to complete.
  - passwords follow a ANSWER_TIMEXXX format which allow them to be easily evaluated for both accuracy and latency
