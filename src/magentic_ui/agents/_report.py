import asyncio
from pathlib import Path
import tempfile
from typing import AsyncGenerator, List, Sequence, Optional, Dict, Any, Union
from typing import Mapping
from loguru import logger
from datetime import datetime
from pydantic import Field, BaseModel
from autogen_core import CancellationToken, ComponentModel, Component
from autogen_core.models import (
    ChatCompletionClient,
    SystemMessage,
)
from typing_extensions import Self
import re

from autogen_agentchat.agents import BaseChatAgent
from autogen_core.model_context import (
    ChatCompletionContext,
    TokenLimitedChatCompletionContext,
)
from autogen_agentchat.base import Response
from autogen_agentchat.state import BaseState
from autogen_agentchat.messages import (
    BaseAgentEvent,
    BaseChatMessage,
    TextMessage,
    MessageFactory,
)

from ..utils import thread_to_context
from ..approval_guard import BaseApprovalGuard
from ..guarded_action import ApprovalDeniedError, TrivialGuardedAction
from magentic_ui.agents._prompt import (
    REPORT_TEMPLATE_OUTLINE_PROMPT,
    REPORT_FREE_OUTLINE_PROMPT,
    REPORT_SECTION_WRITING_PROMPT,
    REPORT_REVIEW_PROMPT,
    REPORT_SYSTEM_PROMPT_TEMPLATE
)
from loguru import logger as trace_logger


class ReportSection(BaseModel):
    """æŠ¥å‘Šç« èŠ‚æ¨¡å‹"""
    title: str
    content: str
    order: int
    is_completed: bool = False


class ReportOutline(BaseModel):
    """æŠ¥å‘Šå¤§çº²æ¨¡å‹"""
    title: str
    sections: List[Dict[str, Any]]
    introduction: str
    conclusion: str
    template_type: str = "default"  # æ·»åŠ æ¨¡æ¿ç±»å‹


class TaskAnalysisResult(BaseModel):
    """ä»»åŠ¡åˆ†æç»“æœ"""
    need_outline: bool = False
    need_chapter_writing: bool = False
    report_type: str = "default"  # æŠ¥å‘Šç±»å‹
    task_description: str = ""


# é¢„è®¾å¤§çº²æ¨¡æ¿
OUTLINE_TEMPLATES = {
    "default": {
        "name": "é€šç”¨è°ƒç ”æŠ¥å‘Š",
        "sections": [
            {"title": "èƒŒæ™¯ä»‹ç»", "description": "ä»‹ç»è°ƒç ”èƒŒæ™¯ã€ç›®çš„å’Œæ„ä¹‰"},
            {"title": "è°ƒç ”æ–¹æ³•", "description": "è¯´æ˜è°ƒç ”æ–¹æ³•ã€æ•°æ®æ¥æºå’Œåˆ†ææ–¹æ³•"},
            {"title": "è°ƒç ”ç»“æœ", "description": "è¯¦ç»†é˜è¿°è°ƒç ”å‘ç°å’Œå…³é”®ç»“æœ"},
            {"title": "åˆ†æè®¨è®º", "description": "å¯¹è°ƒç ”ç»“æœè¿›è¡Œæ·±å…¥åˆ†æå’Œè®¨è®º"},
            {"title": "ç»“è®ºå»ºè®®", "description": "æ€»ç»“ç»“è®ºå¹¶æå‡ºç›¸å…³å»ºè®®"}
        ]
    },
    "data_analysis": {
        "name": "æ•°æ®åˆ†ææŠ¥å‘Š",
        "sections": [
            {"title": "æ•°æ®æ¦‚è§ˆ", "description": "ä»‹ç»æ•°æ®æ¦‚è§ˆã€æ•°æ®æ¥æºå’Œåˆ†ææ–¹æ³•"},
            {"title": "æ•°æ®åˆ†æ", "description": "è¯¦ç»†é˜è¿°æ•°æ®åˆ†æå’Œå…³é”®ç»“æœ"},
            {"title": "æ•°æ®ç»“è®º", "description": "å¯¹æ•°æ®åˆ†æç»“æœè¿›è¡Œæ€»ç»“å’Œç»“è®º"},
            {"title": "æ•°æ®å»ºè®®", "description": "å¯¹æ•°æ®åˆ†æç»“æœæå‡ºç›¸å…³å»ºè®®"}
        ]
    },
    "technology": {
        "name": "ç§‘æŠ€ç±»è°ƒç ”æŠ¥å‘Š",
        "sections": [
            {"title": "æŠ€æœ¯èƒŒæ™¯", "description": "ä»‹ç»ç›¸å…³æŠ€æœ¯èƒŒæ™¯å’Œå‘å±•ç°çŠ¶"},
            {"title": "æŠ€æœ¯åˆ†æ", "description": "è¯¦ç»†åˆ†ææŠ€æœ¯ç‰¹ç‚¹ã€ä¼˜åŠ¿å’Œå±€é™æ€§"},
            {"title": "å¸‚åœºåº”ç”¨", "description": "åˆ†ææŠ€æœ¯åœ¨å¸‚åœºä¸­çš„åº”ç”¨æƒ…å†µ"},
            {"title": "å‘å±•è¶‹åŠ¿", "description": "é¢„æµ‹æŠ€æœ¯æœªæ¥å‘å±•è¶‹åŠ¿"},
            {"title": "é£é™©è¯„ä¼°", "description": "è¯„ä¼°æŠ€æœ¯åº”ç”¨çš„é£é™©å’ŒæŒ‘æˆ˜"},
            {"title": "å»ºè®®æªæ–½", "description": "æå‡ºæŠ€æœ¯åº”ç”¨å’Œå‘å±•å»ºè®®"}
        ]
    },
    "finance": {
        "name": "é‡‘èç±»è°ƒç ”æŠ¥å‘Š",
        "sections": [
            {"title": "å¸‚åœºæ¦‚å†µ", "description": "åˆ†æé‡‘èå¸‚åœºæ•´ä½“æ¦‚å†µå’Œç¯å¢ƒ"},
            {"title": "äº§å“åˆ†æ", "description": "è¯¦ç»†åˆ†æé‡‘èäº§å“ç‰¹ç‚¹å’Œè¡¨ç°"},
            {"title": "é£é™©è¯„ä¼°", "description": "è¯„ä¼°æŠ•èµ„é£é™©å’Œå¸‚åœºé£é™©"},
            {"title": "æ”¶ç›Šåˆ†æ", "description": "åˆ†æé¢„æœŸæ”¶ç›Šå’Œå†å²è¡¨ç°"},
            {"title": "æ”¿ç­–å½±å“", "description": "åˆ†æç›¸å…³æ”¿ç­–å¯¹å¸‚åœºçš„å½±å“"},
            {"title": "æŠ•èµ„å»ºè®®", "description": "æä¾›æŠ•èµ„å»ºè®®å’Œç­–ç•¥"}
        ]
    },
    "code_design": {
        "name": "ä»£ç è®¾è®¡æ–‡æ¡£",
        "sections": [
            {"title": "éœ€æ±‚åˆ†æ", "description": "è¯¦ç»†åˆ†æåŠŸèƒ½éœ€æ±‚å’ŒéåŠŸèƒ½éœ€æ±‚"},
            {"title": "ç³»ç»Ÿæ¶æ„", "description": "è®¾è®¡ç³»ç»Ÿæ•´ä½“æ¶æ„å’Œæ¨¡å—åˆ’åˆ†"},
            {"title": "æ¥å£è®¾è®¡", "description": "å®šä¹‰å„æ¨¡å—é—´çš„æ¥å£å’Œæ•°æ®æ ¼å¼"},
            {"title": "æ•°æ®åº“è®¾è®¡", "description": "è®¾è®¡æ•°æ®åº“è¡¨ç»“æ„å’Œå…³ç³»"},
            {"title": "å®ç°ç»†èŠ‚", "description": "æè¿°å…³é”®åŠŸèƒ½çš„å®ç°ç»†èŠ‚"},
            {"title": "æµ‹è¯•æ–¹æ¡ˆ", "description": "åˆ¶å®šæµ‹è¯•è®¡åˆ’å’Œæµ‹è¯•ç”¨ä¾‹"}
        ]
    }
}


async def _analyze_task_requirements(
    chat_history: List[BaseChatMessage],
    model_client: ChatCompletionClient,
    model_context: ChatCompletionContext,
    cancellation_token: CancellationToken
) -> TaskAnalysisResult:
    """ä½¿ç”¨å¤§æ¨¡å‹åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œåˆ¤æ–­éœ€è¦æ‰§è¡Œå“ªäº›æ­¥éª¤"""
    
    # æ„å»ºåˆ†ææç¤º
    latest_message = ""
    if chat_history:
        latest_msg = chat_history[-1]
        latest_message = str(getattr(latest_msg, 'content', latest_msg))
    
    # æ”¶é›†å¯¹è¯å†å²å†…å®¹
    history_content = ""
    for msg in chat_history[-10:]:  # åªå–æœ€è¿‘10æ¡æ¶ˆæ¯
        content = str(getattr(msg, 'content', ''))
        if content:
            history_content += f"- {content[:200]}...\n"
    
    analysis_prompt = f"""
    è¯·åˆ†æä»¥ä¸‹ä»»åŠ¡è¯·æ±‚å’Œå¯¹è¯å†å²ï¼Œåˆ¤æ–­ç”¨æˆ·å¸Œæœ›æ‰§è¡Œå“ªäº›æ“ä½œï¼š

    å½“å‰ä»»åŠ¡è¯·æ±‚ï¼š
    {latest_message}

    å¯¹è¯å†å²ï¼ˆæœ€è¿‘å†…å®¹ï¼‰ï¼š
    {history_content}

    è¯·åˆ†æå¹¶åˆ¤æ–­ï¼š
    1. æ˜¯å¦éœ€è¦ç”ŸæˆæŠ¥å‘Šå¤§çº²ï¼Ÿ
    2. æ˜¯å¦éœ€è¦é€ç« ç¼–å†™å†…å®¹ï¼Ÿ
    4. æŠ¥å‘Šç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆ{'/'.join(OUTLINE_TEMPLATES.keys())}ï¼‰

    åˆ¤æ–­è§„åˆ™ï¼š
    - å¦‚æœä»»åŠ¡è¦æ±‚è¿›è¡Œå†™ä½œï¼Œä¸”å¯¹è¯å†å²ä¸­æ²¡æœ‰å¤§çº²ï¼Œåˆ™éœ€è¦ç”Ÿæˆå¤§çº²
    - å¦‚æœç”¨æˆ·è¦æ±‚è¿›è¡Œå®Œæ•´çš„å†™ä½œï¼Œä¸”å¯¹è¯å†å²ä¸­æ²¡æœ‰å…·ä½“ç« èŠ‚çš„å†™ä½œå†…å®¹ï¼Œåˆ™éœ€è¦é€ç« ç¼–å†™
    - å¦‚æœå¯¹è¯å†å²ä¸­å·²æœ‰å¤§çº²ä½†ç”¨æˆ·è¦æ±‚å†™å†…å®¹ï¼Œåˆ™åªéœ€è¦é€ç« ç¼–å†™

    è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š
    {{
        "need_outline": true/false,
        "need_chapter_writing": true/false,
        "report_type": "{'/'.join(OUTLINE_TEMPLATES.keys())}",
        "task_description": "ä»»åŠ¡æè¿°"
    }}
    """
    
    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œåˆ†æ
    await model_context.clear()
    await model_context.add_message(SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡åˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨åˆ†æç”¨æˆ·çš„æŠ¥å‘Šç”Ÿæˆéœ€æ±‚ã€‚"))
    from autogen_core.models import UserMessage
    await model_context.add_message(UserMessage(content=analysis_prompt, source="user"))
    
    token_limited_context = await model_context.get_messages()
    
    result = await model_client.create(
        messages=token_limited_context, 
        cancellation_token=cancellation_token
    )
    
    # è§£æç»“æœ
    result_content = ""
    if result.content:
        if isinstance(result.content, str):
            result_content = result.content
        else:
            result_content = str(result.content)
    
    # å°è¯•è§£æJSON
    try:
        import json
        # æå–JSONéƒ¨åˆ†
        json_match = re.search(r'\{.*\}', result_content, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            analysis_data = json.loads(json_str)
            
            return TaskAnalysisResult(
                need_outline=analysis_data.get("need_outline", False),
                need_chapter_writing=analysis_data.get("need_chapter_writing", False),
                report_type=analysis_data.get("report_type", "default"),
                task_description=analysis_data.get("task_description", latest_message)
            )
    except Exception as e:
        logger.warning(f"è§£æä»»åŠ¡åˆ†æç»“æœå¤±è´¥: {e}")
    
    # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•è§„åˆ™åˆ¤æ–­
    task_lower = latest_message.lower()
    report_type = "default"
    
    if any(word in task_lower for word in ["ç§‘æŠ€", "æŠ€æœ¯", "technology", "tech"]):
        report_type = "technology"
    elif any(word in task_lower for word in ["æ•°æ®", "åˆ†æ", "data", "analysis", "æ•°æ®åˆ†æ"]):
        report_type = "data_analysis"
    elif any(word in task_lower for word in ["é‡‘è", "æŠ•èµ„", "finance", "financial"]):
        report_type = "finance"
    elif any(word in task_lower for word in ["ä»£ç ", "è®¾è®¡", "code", "design", "è½¯ä»¶", "ç³»ç»Ÿ"]):
        report_type = "code_design"
    
    need_outline = "å¤§çº²" in latest_message or "outline" in task_lower
    need_chapter_writing = any(word in latest_message for word in ["æ’°å†™", "ç¼–å†™", "å†™ä½œ", "ç« èŠ‚"])
    
    return TaskAnalysisResult(
        need_outline=need_outline,
        need_chapter_writing=need_chapter_writing,
        report_type=report_type,
        task_description=latest_message
    )


def _extract_sources_from_context(context_messages: List[BaseChatMessage]) -> List[dict[str, str]]:
    """ä»ä¸Šä¸‹æ–‡ä¸­æå–ä¿¡æ¯æ¥æº"""
    sources: List[dict[str, str]] = []

    for msg in context_messages:
        content = str(getattr(msg, 'content', ''))
        trace_logger.info(f"æå–æ¥æº: {content}")
        if content:
            source_pattern = r'URL:\s*([^\s\n]+)[\s\n]+æ ‡é¢˜:\s*(.+?)\s*å†…å®¹æ€»ç»“:\s*(.+?)(?=\n\n---|$)'
            res = re.findall(source_pattern, content, re.DOTALL)
            if res:
                trace_logger.info(f"å¼•ç”¨æ¥æº: {res}")
                for source in res:
                    sources.append({
                        "url": source[0],
                        "title": source[1],
                        "summary": source[2]
                    })
            
            # deep_search_pattern = r'^æ·±åº¦æœç´¢å®Œæˆ'
            # source_pattern = r'URL:(.+)æ ‡é¢˜:(.+)å†…å®¹æ€»ç»“:(.+)'
            # deep_search_flag = re.search(deep_search_pattern, content, re.DOTALL)
            # if deep_search_flag:
            #     deep_search_res = content.split("\n\n---\n\n")
            #     for res in deep_search_res:
            #         res = re.findall(source_pattern, res, re.DOTALL)
            #         if res:
            #             trace_logger.info(f"å¼•ç”¨æ¥æº: {res}")
            #             for source in res:
            #                 sources.append({
            #                     "url": source[0],
            #                     "title": source[1],
            #                     "summary": source[2]
            #                 })
            # else:
            #     # æŸ¥æ‰¾URL:...æ ‡é¢˜:...å†…å®¹æ€»ç»“:...æ ¼å¼çš„æ¶ˆæ¯ï¼Œå¹¶æå–å‡ºæ¶ˆæ¯å†…çš„æ ‡é¢˜å’Œurl
            #     res = re.findall(source_pattern, content, re.DOTALL)
            #     if res:
            #         trace_logger.info(f"å¼•ç”¨æ¥æº: {res}")
            #         for source in res:
            #             sources.append({
            #                 "url": source[0],
            #                 "title": source[1],
            #                 "summary": source[2]
            #             })
                    
    return sources


def _extract_outline_from_history(chat_history: List[BaseChatMessage]) -> Optional[ReportOutline]:
    """ä»å¯¹è¯å†å²ä¸­æå–å¤§çº²ä¿¡æ¯"""
    for msg in reversed(chat_history):
        content = str(getattr(msg, 'content', ''))
        if content and ("æŠ¥å‘Šå¤§çº²" in content or "outline" in content.lower() or content.startswith("# ")):
            return _extract_outline_from_text(content, "default")
    return None


def _generate_outline_from_template(template_type: str, task_description: str) -> str:
    """æ ¹æ®æ¨¡æ¿ç”Ÿæˆå¤§çº²"""
    if template_type not in OUTLINE_TEMPLATES:
        template_type = "default"
    
    template = OUTLINE_TEMPLATES[template_type]
    
    outline_content = f"# {template['name']}\n\n"
    
    for section in template['sections']:
        section_dict = section if isinstance(section, dict) else {}
        outline_content += f"## {section_dict.get('title', '')}\n{section_dict.get('description', '')}\n\n"
    
    return outline_content


def _extract_outline_from_text(text: str, template_type: str = "default") -> ReportOutline:
    """ä»æ–‡æœ¬ä¸­æå–æŠ¥å‘Šå¤§çº²"""
    lines = text.split('\n')
    title = ""
    sections: List[Dict[str, Any]] = []
    introduction = ""
    conclusion = ""
    
    current_section: Optional[Dict[str, Any]] = None
    in_intro = False
    in_conclusion = False
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # æ£€æµ‹æ ‡é¢˜
        if line.startswith('# '):
            title = line[2:].strip()
        elif line.startswith('## '):
            # æ–°çš„ç« èŠ‚
            section_title = line[3:].strip()
            if section_title.lower() in ['å¼•è¨€', 'introduction']:
                in_intro = True
                in_conclusion = False
                if current_section:
                    sections.append(current_section)
                current_section = None
            elif section_title.lower() in ['ç»“è®º', 'conclusion']:
                in_conclusion = True
                in_intro = False
                if current_section:
                    sections.append(current_section)
                current_section = None
            else:
                if current_section:
                    sections.append(current_section)
                current_section = {
                    'title': section_title,
                    'description': '',
                    'order': len(sections) + 1
                }
                in_intro = False
                in_conclusion = False
        else:
            # å†…å®¹è¡Œ
            if in_intro:
                introduction += line + '\n'
            elif in_conclusion:
                conclusion += line + '\n'
            elif current_section:
                current_section['description'] = str(current_section.get('description', '')) + line + '\n'
    
    if current_section:
        sections.append(current_section)
    
    return ReportOutline(
        title=title or "è°ƒæŸ¥ç ”ç©¶æŠ¥å‘Š",
        sections=sections,
        introduction=introduction.strip(),
        conclusion=conclusion.strip(),
        template_type=template_type
    )


async def _invoke_report_action_guard(
    thread: Sequence[BaseChatMessage | BaseAgentEvent],
    delta: Sequence[BaseChatMessage | BaseAgentEvent],
    report_message: TextMessage,
    agent_name: str,
    model_client: ChatCompletionClient,
    approval_guard: BaseApprovalGuard | None,
    action_type: str = "report_generation"
) -> None:
    """è°ƒç”¨æŠ¥å‘Šç”Ÿæˆçš„å®¡æ‰¹å®ˆå«"""
    guarded_action = TrivialGuardedAction(action_type, baseline_override="maybe")
    
    assert delta[-1] == report_message
    
    thread_list = list(thread) + list(delta)
    
    context = thread_to_context(
        thread_list,
        agent_name,
        is_multimodal=model_client.model_info["vision"],
    )
    
    action_description_for_user = TextMessage(
        content=f"æ˜¯å¦è¦æ‰§è¡Œ{action_type}æ“ä½œï¼Ÿ",
        source=agent_name,
    )
    
    await guarded_action.invoke_with_approval(
        {}, report_message, context, approval_guard, action_description_for_user
    )


async def _generate_report_with_review(
    system_prompt: str,
    thread: Sequence[BaseChatMessage],
    agent_name: str,
    model_client: ChatCompletionClient,
    work_dir: Path,
    max_review_rounds: int,
    cancellation_token: CancellationToken,
    model_context: ChatCompletionContext,
    approval_guard: BaseApprovalGuard | None,
    task_analysis: TaskAnalysisResult,
) -> AsyncGenerator[Union[TextMessage, bool], None]:
    """ç”ŸæˆæŠ¥å‘Šå¹¶è¿›è¡Œå®¡æŸ¥æ¶¦è‰²çš„ä¸»è¦æµç¨‹"""
    
    delta: List[Union[BaseChatMessage, BaseAgentEvent]] = []
    report_generated = False
    
    # æå–ä¿¡æ¯æ¥æº
    sources = _extract_sources_from_context(list(thread))
    
    try:
        outline: Optional[ReportOutline] = None
        full_report_content = ""
        
        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå¤§çº²ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if task_analysis.need_outline:
            if task_analysis.report_type != "default":
                # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆå¤§çº²ï¼ŒTODO ç”Ÿæˆå¤§çº²çš„æ ‡é¢˜å³å¯ä¸è¦ç”Ÿæˆå†…å®¹
                template_outline = _generate_outline_from_template(
                    task_analysis.report_type, 
                    task_analysis.task_description
                )
                
                outline_prompt = REPORT_TEMPLATE_OUTLINE_PROMPT.format(
                    task_description=task_analysis.task_description,
                    report_type_name=OUTLINE_TEMPLATES[task_analysis.report_type]['name'],
                    template_outline=template_outline
                )
            else:
                # ä¸ä½¿ç”¨æ¨¡æ¿ï¼Œè‡ªç”±ç”Ÿæˆå¤§çº²
                outline_prompt = REPORT_FREE_OUTLINE_PROMPT.format(
                    task_description=task_analysis.task_description
                )
            
            current_thread = (
                list(thread)
                + list(delta)
                + [TextMessage(source="user", content=outline_prompt)]
            )
            
            context = [SystemMessage(content=system_prompt)] + thread_to_context(
                current_thread,
                agent_name,
                is_multimodal=model_client.model_info["vision"],
            )
            
            # ç”Ÿæˆå¤§çº²
            await model_context.clear()
            for msg in context:
                await model_context.add_message(msg)
            token_limited_context = await model_context.get_messages()
            
            outline_result = await model_client.create(
                messages=token_limited_context, cancellation_token=cancellation_token
            )
            
            # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²ç±»å‹
            outline_content = ""
            if outline_result.content:
                if isinstance(outline_result.content, str):
                    outline_content = outline_result.content
                else:
                    outline_content = str(outline_result.content)
            
            outline_msg = TextMessage(
                source=agent_name + "-outline",
                metadata={"internal": "no", "type": "report_outline"},
                content=f"ğŸ“‹ **æŠ¥å‘Šå¤§çº²ç”Ÿæˆå®Œæˆ**\n\n{outline_content}",
            )
            delta.append(outline_msg)
            yield outline_msg
            
            # è§£æå¤§çº²
            outline = _extract_outline_from_text(outline_content, task_analysis.report_type)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å®¡æ‰¹
            if approval_guard is not None:
                await _invoke_report_action_guard(
                    thread=thread,
                    delta=delta,
                    report_message=outline_msg,
                    agent_name=agent_name,
                    model_client=model_client,
                    approval_guard=approval_guard,
                    action_type="outline_generation"
                )
        
        # ç¬¬äºŒæ­¥ï¼šé€ç« èŠ‚å†™ä½œï¼ˆå¦‚æœéœ€è¦ï¼‰
        if task_analysis.need_chapter_writing:
            if outline is None:
                # ä»å¯¹è¯å†å²ä¸­æå–å¤§çº²
                outline = _extract_outline_from_history(list(thread))
                
                if outline is None:
                    # å¦‚æœä»ç„¶æ²¡æœ‰å¤§çº²ï¼Œç”Ÿæˆä¸€ä¸ªé»˜è®¤å¤§çº²
                    default_outline = _generate_outline_from_template("default", task_analysis.task_description)
                    outline = _extract_outline_from_text(default_outline, "default")
            
            report_sections: List[ReportSection] = []
            full_report_content = f"# {outline.title}\n\n"
            
            # åªå†™å„ä¸ªç« èŠ‚ï¼Œä¸å†™å¼•è¨€å’Œç»“è®º
            for i, section in enumerate(outline.sections):
                section_title = str(section.get('title', f'ç« èŠ‚{i+1}'))
                section_description = str(section.get('description', ''))
                
                # TODO å°†sourcesæ·»åŠ åˆ°section_promptä¸­
                section_prompt = REPORT_SECTION_WRITING_PROMPT.format(
                    section_number=i+1,
                    section_title=section_title,
                    section_description=section_description,
                    sources="\n\n".join([f"[{i+1}]{source['title']} - {source['url']}\n{source['summary']}" for i, source in enumerate(sources)]) if sources else "æ— ç‰¹å®šæ¥æº",
                    task_description=task_analysis.task_description
                )
                
                trace_logger.info(f"section_prompt: {section_prompt}")
                
                current_thread = (
                    list(thread)
                    + list(delta)
                    + [TextMessage(source="user", content=section_prompt)]
                )
                
                context = [SystemMessage(content=system_prompt)] + thread_to_context(
                    current_thread,
                    agent_name,
                    is_multimodal=model_client.model_info["vision"],
                )
                
                await model_context.clear()
                for msg in context:
                    await model_context.add_message(msg)
                token_limited_context = await model_context.get_messages()
                
                section_result = await model_client.create(
                    messages=token_limited_context, cancellation_token=cancellation_token
                )
                
                # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²ç±»å‹
                section_content = ""
                if section_result.content:
                    if isinstance(section_result.content, str):
                        section_content = section_result.content
                    else:
                        section_content = str(section_result.content)
                
                section_msg = TextMessage(
                    source=agent_name + "-writer",
                    metadata={"internal": "no", "type": "section_content"},
                    content=f"âœï¸ **ç¬¬{i+1}ç« èŠ‚ã€Š{section_title}ã€‹æ’°å†™å®Œæˆ**\n\n{section_content}",
                )
                delta.append(section_msg)
                yield section_msg
                
                full_report_content += f"## {section_title}\n\n{section_content}\n\n"
                
                # æå–è¯¥ç« èŠ‚å¼•ç”¨çš„æ¥æº
                section_sources: List[dict[str, str]] = []
                for source in sources:
                    if source['url'] in section_content:
                        section_sources.append(source)
                
                report_sections.append(ReportSection(
                    title=section_title,
                    content=section_content,
                    order=i+1,
                    is_completed=True
                ))
            
            # TODO å‚è€ƒæ¥æºä¿®æ”¹
            if sources:
                full_report_content += "## å‚è€ƒæ¥æº\n\n"
                for i, source in enumerate(sources):
                    full_report_content += f"[{i+1}]{source['title']} - {source['url']}\n"
                full_report_content += "\n"
        
        # # ç¬¬ä¸‰æ­¥ï¼šå®¡æŸ¥å’Œæ¶¦è‰²ï¼ˆå¦‚æœæœ‰å†…å®¹éœ€è¦å®¡æŸ¥ï¼‰
        # if task_analysis.need_chapter_writing and full_report_content:
        #     for review_round in range(max_review_rounds):
        #         review_prompt = REPORT_REVIEW_PROMPT.format(
        #             full_report_content=full_report_content
        #         )
                
        #         current_thread = (
        #             list(thread)
        #             + list(delta)
        #             + [TextMessage(source="user", content=review_prompt)]
        #         )
                
        #         context = [SystemMessage(content=system_prompt)] + thread_to_context(
        #             current_thread,
        #             agent_name,
        #             is_multimodal=model_client.model_info["vision"],
        #         )
                
        #         await model_context.clear()
        #         for msg in context:
        #             await model_context.add_message(msg)
        #         token_limited_context = await model_context.get_messages()
                
        #         review_result = await model_client.create(
        #             messages=token_limited_context, cancellation_token=cancellation_token
        #         )
                
        #         # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²ç±»å‹
        #         review_content = ""
        #         if review_result.content:
        #             if isinstance(review_result.content, str):
        #                 review_content = review_result.content
        #             else:
        #                 review_content = str(review_result.content)
                
        #         review_msg = TextMessage(
        #             source=agent_name + "-reviewer",
        #             metadata={"internal": "no", "type": "report_review"},
        #             content=f"ğŸ” **ç¬¬{review_round + 1}è½®å®¡æŸ¥æ¶¦è‰²å®Œæˆ**\n\n{review_content}...",
        #         )
        #         delta.append(review_msg)
        #         yield review_msg
                
        #         # æ›´æ–°æŠ¥å‘Šå†…å®¹
        #         full_report_content = review_content
        
        # ç¬¬å››æ­¥ï¼šä¿å­˜MDæ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if full_report_content:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_type_name = OUTLINE_TEMPLATES.get(task_analysis.report_type, {}).get('name', 'è°ƒæŸ¥ç ”ç©¶æŠ¥å‘Š')
            filename = f"{report_type_name}_{timestamp}.md"
            file_path = work_dir / filename
            
            # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
            work_dir.mkdir(parents=True, exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(full_report_content)
            
            save_msg = TextMessage(
                source=agent_name + "-saver",
                metadata={"internal": "no", "type": "file_save"},
                content=f"ğŸ’¾ **æŠ¥å‘Šå·²ä¿å­˜**\n\næ–‡ä»¶è·¯å¾„ï¼š{file_path}\næ–‡ä»¶åï¼š{filename}",
            )
            delta.append(save_msg)
            yield save_msg
        
        report_generated = True
        
    except Exception as e:
        error_msg = TextMessage(
            source=agent_name + "-error",
            metadata={"internal": "no", "type": "error"},
            content=f"âŒ **æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯**\n\né”™è¯¯ä¿¡æ¯ï¼š{str(e)}",
        )
        delta.append(error_msg)
        yield error_msg
    
    yield report_generated


class ReportAgentConfig(BaseModel):
    name: str
    model_client: ComponentModel
    description: str = """
    ä¸€ä¸ªä¸“é—¨ç”¨äºç”Ÿæˆè°ƒæŸ¥ç ”ç©¶æŠ¥å‘Šçš„æ™ºèƒ½ä»£ç†ã€‚
    å®ƒèƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆç»“æ„åŒ–çš„è°ƒæŸ¥ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…æ‹¬å¤§çº²åˆ¶å®šã€é€ç« å†™ä½œã€å®¡æŸ¥æ¶¦è‰²ç­‰å®Œæ•´æµç¨‹ã€‚
    æœ€ç»ˆè¾“å‡ºä¸“ä¸šçš„Markdownæ ¼å¼æŠ¥å‘Šæ–‡ä»¶ã€‚
    """
    max_review_rounds: int = 1
    auto_save: bool = True


class ReportAgentState(BaseState):
    chat_history: List[BaseChatMessage] = Field(default_factory=list)
    current_report: Optional[Dict[str, Any]] = None
    type: str = Field(default="ReportAgentState")


class ReportAgent(BaseChatAgent, Component[ReportAgentConfig]):
    """ä¸“é—¨ç”¨äºç”Ÿæˆè°ƒæŸ¥ç ”ç©¶æŠ¥å‘Šçš„æ™ºèƒ½ä»£ç†
    
    è¯¥ä»£ç†èƒ½å¤Ÿï¼š
    1. æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ç”ŸæˆæŠ¥å‘Šå¤§çº²
    2. é€ç« èŠ‚æ’°å†™è¯¦ç»†å†…å®¹
    3. å®¡æŸ¥å’Œæ¶¦è‰²æŠ¥å‘Š
    4. è¾“å‡ºä¸“ä¸šçš„Markdownæ ¼å¼æŠ¥å‘Šæ–‡ä»¶
    """
    
    component_type = "agent"
    component_config_schema = ReportAgentConfig
    component_provider_override = "magentic_ui.agents.ReportAgent"
    
    DEFAULT_DESCRIPTION = """
    ä¸€ä¸ªä¸“é—¨ç”¨äºç”Ÿæˆè°ƒæŸ¥ç ”ç©¶æŠ¥å‘Šçš„æ™ºèƒ½ä»£ç†ã€‚
    å®ƒèƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆç»“æ„åŒ–çš„è°ƒæŸ¥ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…æ‹¬å¤§çº²åˆ¶å®šã€é€ç« å†™ä½œã€å®¡æŸ¥æ¶¦è‰²ç­‰å®Œæ•´æµç¨‹ã€‚
    æ³¨æ„ï¼šå®ƒåªèƒ½å¤ŸåŸºäºå·²æœé›†å¹¶æ•´ç†å¥½çš„ä¿¡æ¯ç”ŸæˆæŠ¥å‘Šï¼Œä¸æ”¯æŒä¿¡æ¯çš„æœé›†å’Œæ•´ç†ã€‚
    """
    
    system_prompt_template = REPORT_SYSTEM_PROMPT_TEMPLATE.format(
        date_today=datetime.now().strftime("%Y-%m-%d")
    )
    
    def __init__(
        self,
        name: str,
        model_client: ChatCompletionClient,
        model_context_token_limit: int = 128000,
        description: str = DEFAULT_DESCRIPTION,
        max_review_rounds: int = 2,
        auto_save: bool = True,
        work_dir: Path | str | None = None,
        approval_guard: BaseApprovalGuard | None = None,
    ) -> None:
        """åˆå§‹åŒ–ReportAgent
        
        Args:
            name: ä»£ç†åç§°
            model_client: è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯
            model_context_token_limit: æ¨¡å‹ä¸Šä¸‹æ–‡ä»¤ç‰Œé™åˆ¶
            description: ä»£ç†æè¿°
            max_review_rounds: æœ€å¤§å®¡æŸ¥è½®æ•°
            auto_save: æ˜¯å¦è‡ªåŠ¨ä¿å­˜æŠ¥å‘Š
            work_dir: å·¥ä½œç›®å½•
            approval_guard: å®¡æ‰¹å®ˆå«
        """
        super().__init__(name, description)
        self._model_client = model_client
        self._model_context = TokenLimitedChatCompletionContext(
            model_client, token_limit=model_context_token_limit
        )
        self._chat_history: List[BaseChatMessage] = []
        self._max_review_rounds = max_review_rounds
        self._auto_save = auto_save
        self.is_paused = False
        self._paused = asyncio.Event()
        self._approval_guard = approval_guard
        self._current_report: Optional[Dict[str, Any]] = None
        
        if work_dir is None:
            self._work_dir = Path(tempfile.mkdtemp())
            self._cleanup_work_dir = True
        else:
            self._work_dir = Path(work_dir)
            self._cleanup_work_dir = False
    
    async def lazy_init(self) -> None:
        """å»¶è¿Ÿåˆå§‹åŒ–"""
        pass
    
    async def close(self) -> None:
        """æ¸…ç†èµ„æº"""
        logger.info("Closing ReportAgent...")
        if self._cleanup_work_dir and self._work_dir.exists():
            import shutil
            await asyncio.to_thread(shutil.rmtree, self._work_dir)
        await self._model_client.close()
    
    async def pause(self) -> None:
        """æš‚åœä»£ç†"""
        self.is_paused = True
        self._paused.set()
    
    async def resume(self) -> None:
        """æ¢å¤ä»£ç†"""
        self.is_paused = False
        self._paused.clear()
    
    @property
    def produced_message_types(self) -> Sequence[type[BaseChatMessage]]:
        """è·å–ä»£ç†äº§ç”Ÿçš„æ¶ˆæ¯ç±»å‹"""
        return (TextMessage,)
    
    async def on_messages(
        self, messages: Sequence[BaseChatMessage], cancellation_token: CancellationToken
    ) -> Response:
        """å¤„ç†ä¼ å…¥æ¶ˆæ¯å¹¶è¿”å›å•ä¸ªå“åº”"""
        response: Response | None = None
        async for message in self.on_messages_stream(messages, cancellation_token):
            if isinstance(message, Response):
                response = message
        assert response is not None
        return response
    
    async def on_messages_stream(
        self, messages: Sequence[BaseChatMessage], cancellation_token: CancellationToken
    ) -> AsyncGenerator[BaseAgentEvent | BaseChatMessage | Response, None]:
        """å¤„ç†ä¼ å…¥æ¶ˆæ¯å¹¶äº§ç”Ÿå“åº”æµ"""
        if self.is_paused:
            yield Response(
                chat_message=TextMessage(
                    content="ReportAgent å½“å‰å·²æš‚åœã€‚",
                    source=self.name,
                    metadata={"internal": "yes"},
                )
            )
            return
        
        self._chat_history.extend(messages)
        inner_messages: List[BaseChatMessage] = []
        
        # ä½¿ç”¨å¤§æ¨¡å‹åˆ†æä»»åŠ¡éœ€æ±‚
        task_analysis = await _analyze_task_requirements(
            self._chat_history, 
            self._model_client, 
            self._model_context, 
            cancellation_token
        )
        
        # è¾“å‡ºä»»åŠ¡åˆ†æç»“æœ
        analysis_msg = TextMessage(
            source=self.name + "-analyzer",
            metadata={"internal": "no", "type": "task_analysis"},
            content=f"ğŸ“Š **ä»»åŠ¡åˆ†æå®Œæˆ**\n\n"
                   f"- æŠ¥å‘Šç±»å‹ï¼š{OUTLINE_TEMPLATES.get(task_analysis.report_type, {}).get('name', 'é€šç”¨æŠ¥å‘Š')}\n"
                   f"- éœ€è¦ç”Ÿæˆå¤§çº²ï¼š{'æ˜¯' if task_analysis.need_outline else 'å¦'}\n"
                   f"- éœ€è¦æ’°å†™ç« èŠ‚ï¼š{'æ˜¯' if task_analysis.need_chapter_writing else 'å¦'}\n"
                   f"- ä»»åŠ¡æè¿°ï¼š{task_analysis.task_description[:100]}..."
        )
        inner_messages.append(analysis_msg)
        
        # è®¾ç½®å–æ¶ˆä»¤ç‰Œ
        report_generation_token = CancellationToken()
        cancellation_token.add_callback(lambda: report_generation_token.cancel())
        
        # ç›‘æ§æš‚åœäº‹ä»¶
        async def monitor_pause() -> None:
            await self._paused.wait()
            report_generation_token.cancel()
        
        monitor_pause_task = asyncio.create_task(monitor_pause())
        
        system_prompt = self.system_prompt_template
        
        try:
            report_generated = False
            
            # è¿è¡ŒæŠ¥å‘Šç”Ÿæˆæµç¨‹
            async for msg in _generate_report_with_review(
                system_prompt=system_prompt,
                thread=self._chat_history,
                agent_name=self.name,
                model_client=self._model_client,
                work_dir=self._work_dir,
                max_review_rounds=self._max_review_rounds,
                cancellation_token=report_generation_token,
                model_context=self._model_context,
                approval_guard=self._approval_guard,
                task_analysis=task_analysis,
            ):
                if isinstance(msg, bool):
                    report_generated = msg
                    break
                inner_messages.append(msg)
                self._chat_history.append(msg)
                yield msg
            
            # ç”Ÿæˆæœ€ç»ˆå“åº”
            if report_generated:
                combined_output = ""
                for txt_msg in inner_messages:
                    assert isinstance(txt_msg, TextMessage)
                    combined_output += f"{txt_msg.content}\n\n"
                
                final_response_msg = TextMessage(
                    source=self.name,
                    metadata={"internal": "yes"},
                    content=f"ğŸ“„ **æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å®Œæˆ**\n\n{combined_output}" or "æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œä½†æ²¡æœ‰è¾“å‡ºå†…å®¹ã€‚",
                )
                
                yield Response(
                    chat_message=final_response_msg, inner_messages=inner_messages
                )
            else:
                yield Response(
                    chat_message=TextMessage(
                        content="æŠ¥å‘Šç”Ÿæˆæœªå®Œæˆã€‚",
                        source=self.name,
                        metadata={"internal": "yes"},
                    ),
                    inner_messages=inner_messages,
                )
                
        except ApprovalDeniedError:
            yield Response(
                chat_message=TextMessage(
                    content="ç”¨æˆ·æœªæ‰¹å‡†æŠ¥å‘Šç”Ÿæˆæ“ä½œã€‚",
                    source=self.name,
                    metadata={"internal": "no"},
                ),
                inner_messages=inner_messages,
            )
        except asyncio.CancelledError:
            yield Response(
                chat_message=TextMessage(
                    content="æŠ¥å‘Šç”Ÿæˆä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆã€‚",
                    source=self.name,
                    metadata={"internal": "yes"},
                ),
                inner_messages=inner_messages,
            )
        except Exception as e:
            logger.error(f"ReportAgent å‘ç”Ÿé”™è¯¯: {e}")
            self._chat_history.append(
                TextMessage(
                    content=f"æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}",
                    source=self.name,
                )
            )
            yield Response(
                chat_message=TextMessage(
                    content=f"ReportAgent å‘ç”Ÿé”™è¯¯: {e}",
                    source=self.name,
                    metadata={"internal": "no"},
                ),
                inner_messages=inner_messages,
            )
        finally:
            try:
                monitor_pause_task.cancel()
                await monitor_pause_task
            except asyncio.CancelledError:
                pass
    
    async def on_reset(self, cancellation_token: CancellationToken) -> None:
        """é‡ç½®èŠå¤©å†å²"""
        self._chat_history.clear()
        self._current_report = None
    
    def _to_config(self) -> ReportAgentConfig:
        """è½¬æ¢ä¸ºé…ç½®å¯¹è±¡"""
        return ReportAgentConfig(
            name=self.name,
            model_client=self._model_client.dump_component(),
            description=self.description,
            max_review_rounds=self._max_review_rounds,
            auto_save=self._auto_save,
        )
    
    @classmethod
    def _from_config(cls, config: ReportAgentConfig) -> Self:
        """ä»é…ç½®å¯¹è±¡åˆ›å»ºå®ä¾‹"""
        return cls(
            name=config.name,
            model_client=ChatCompletionClient.load_component(config.model_client),
            description=config.description,
            max_review_rounds=config.max_review_rounds,
            auto_save=config.auto_save,
        )
    
    async def save_state(self) -> Mapping[str, Any]:
        """ä¿å­˜çŠ¶æ€"""
        return {
            "chat_history": [msg.dump() for msg in self._chat_history],
            "current_report": self._current_report,
        }
    
    async def load_state(self, state: Mapping[str, Any]) -> None:
        """åŠ è½½çŠ¶æ€"""
        message_factory = MessageFactory()
        for msg_data in state["chat_history"]:
            msg = message_factory.create(msg_data)
            assert isinstance(msg, BaseChatMessage)
            self._chat_history.append(msg)
        self._current_report = state.get("current_report") 